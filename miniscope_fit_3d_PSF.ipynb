{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to fit an optical model of the lenslets to the captured PSF data. The idea is to give background- and noise-free impulse responses. This will be built on the tensorflow core code that runs the PSF optimization.\n",
    "\n",
    "The problem statement is basically:\n",
    "\n",
    "\n",
    "\n",
    "$$\\arg\\min_{\\theta_l,\\theta_M} \\sum_{z=0}^{N_z-1} \\left\\lVert\\left|F^{-1}diag(P_L)F\\left[U_z(x,y|\\theta_M).*\\exp(-j\\phi(x,y|\\theta_l)\\right]\\right|^2 - b(x,y|z)\\right\\lVert$$\n",
    "\n",
    "where $\\theta_l$ represents a parameterized phase mask (i.e. lenslet locations, zernikes), $\\theta_M$ represents the parameters of the miniscope build, including mask rotations and tip/tilt. $P_L$ is propagation by distance L (in frequency space), $F$ is DFT, $U_z$ is the wavefront in the pupil due to a point source at plane $z$ in front of the GRIN, and $\\phi$ is the phase of the pupil-plane mask. $b(x,y|z)$ is the PSF measured from the as-built system with a point source at distance z-plane $z$.\n",
    "\n",
    "To make this work, initialization is crucial. We will initialize the model with the background subtracted zstack taken from the as-built nanoscribe-based miniscope (``model.target_psf``). We will then generate PSFs with manually entered rotations and focus until a qualitatively close match is found between the recipe and the measured PSF. Once that has been found, we'll use feature matching + ransac (or similar) to find a homography between the measured PSF and the predicted one. The shift an rotation can be directly applied to the coordinates of the lenslets in the design. The magnification will be used to fine-tune the actual object distances (since scale approximately maps to z for small defocuses). With that homography, we'll have the parameters necessary to initialize the lenslet fitting problem fairly well. \n",
    "\n",
    "To summarize:\n",
    "1. Initialize miniscope model with calibration stack as `model.target_psf`\n",
    "\n",
    "2. Manually find rotation/focus to match a single measured PSF to a simulated one (qualitatively)\n",
    "    2. Manually rotate `model.xpos` and `model.ypos`\n",
    "    2. reinitialize model with rotated coordinates\n",
    "    2. generate rotated surface function using `tf_utils.make_lenslet_tf_zern(model)` \n",
    "    2. generate zstacks using `model.gen_psf_stack`\n",
    "    2. Repeat until good match is found\n",
    "\n",
    "3. Find homgraphy between points generated in 2 and target psf\n",
    "4. Use parameters of homography to update model\n",
    "5. Fine tune locations, radii (and possibly zernikes) using gradient descent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import miniscope_utils_tf as tf_utils\n",
    "from miniscope_model import Model as msu_model\n",
    "import scipy as sc\n",
    "import scipy.ndimage as ndim\n",
    "import scipy.misc as misc\n",
    "from scipy import signal\n",
    "import scipy.io\n",
    "from skimage.transform import resize as imresize\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "from IPython import display\n",
    "import cv2 as cv2\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_init_model(model_in, xi, yi, ri, zi,di=-1):\n",
    "    if di is -1:\n",
    "        di = tf.zeros(model_in.Nz,tf.float64)\n",
    "    model_in.xpos.assign(xi)\n",
    "    model_in.ypos.assign(yi)\n",
    "\n",
    "    #model_in.lenslet_offset.assign(offsetinit)\n",
    "    model_in.rlist.assign(ri)\n",
    "    model_in.defocus_offset.assign(di)\n",
    "    if tf.not_equal(tf.size(model.zernlist),0):\n",
    "        model_in.zernlist.assign(zi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zernikes_index = []\n",
    "#model = msu_model(Nlenslets = 29, aberrations = False, zernikes = zernikes_index,loss_type='psf_error',psf_scale=1e2,\n",
    "#                  lenslet_CA=0.2,lenslet_spacing = 'uniform')  # zsampling options: 'fixed' or 'uniform_random'\n",
    "\n",
    "# model = msu_model(Nlenslets = 37, aberrations = False, zernikes = zernikes_index,loss_type='psf_error',psf_scale=1e2,\n",
    "#                   lenslet_CA=0.2e3,lenslet_spacing = 'uniform',psf_file='../psf_meas/nanoscribev1_zstack_june262019_2x_dz40_shifted_center_interp.mat',incoherent_source = True)\n",
    "\n",
    "#../psf_meas/psf_crop_nanoscribe_v1_re-registered.mat\n",
    "model = msu_model(Nlenslets = 37, aberrations = False, zernikes = zernikes_index,loss_type='psf_error',psf_scale=1e2,\n",
    "                  lenslet_CA=0.2e3,lenslet_spacing = 'uniform',psf_file='../psf_meas/psf_crop_nanoscribe_v1_re-registered.mat',incoherent_source = True)\n",
    "\n",
    "#psf_file='../psf_meas/nanoscribev1_zstack_june262019_2x_dz40_shifted.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3735, shape=(10,), dtype=float64, numpy=\n",
       "array([98.59672453, 99.24510999, 99.0255113 , 97.81098796, 95.70625811,\n",
       "       91.62814048, 86.33182633, 81.46963057, 76.66291931, 66.60136769])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targ_psf2 = model.target_psf\n",
    "# targ_psf2 = [cv2.resize(model.target_psf[n].numpy()[model.samples[0]//4:3*model.samples[0]//4,model.samples[1]//4:3*model.samples[1]//4],(model.samples[1],model.samples[0])) for n in range(model.Nz)]\n",
    "# fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "# n = 0\n",
    "# print(np.shape(model.target_psf[n].numpy()[model.samples[0]//4:3*model.samples[0]//4,model.samples[1]//4:3*model.samples[1]//4]))\n",
    "# ax[0].imshow(model.target_psf[n])\n",
    "# ax[1].imshow(targ_psf2[n])\n",
    "# out_dict2 = {'zstack' : targ_psf2}\n",
    "# sc.io.savemat('../psf_meas/nanoscribev1_zstack_june262019_2x_dz40_shifted.mat',out_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the x,y,r,zernikes from a previous run\n",
    "\n",
    "\n",
    "#model_orig = sc.io.loadmat(\"../psf_meas/zstack_sim_test.mat\")\n",
    "#model_orig = sc.io.loadmat(\"../psf_meas/zstack_nanoscribe_recipe.mat\")\n",
    "model_orig = sc.io.loadmat('../l1_GOOD_scaled_nanoscribe_v1_20190813_150813.mat')\n",
    "# xinit = model_orig['xpos'][0].astype(np.float64)*1e3\n",
    "# yinit = model_orig['ypos'][0].astype(np.float64)*1e3\n",
    "# rinit = model_orig['r'][0].astype(np.float64)*1e3\n",
    "\n",
    "xinit = model_orig['xpos'][0].astype(np.float64)\n",
    "yinig = model_orig['ypos'][0].astype(np.float64)\n",
    "rinit = model_orig['rlist'][0].astype(np.float64)\n",
    "zlist = model_orig['defocus_list'][0]\n",
    "zerrlist = model_orig['defocus_correction'][0]\n",
    "#test = model_orig['zern_list']\n",
    "zerninit = test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(array([[1]], dtype=uint8),)]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual initialization with nanoscribed recipe\n",
    "# Randoscope nanoscribe v1 recipe: \n",
    "\n",
    "# xpos=np.array([ 0.18578115,  0.74248238,  0.35555949,  0.10187365, -0.22157956,\n",
    "#        -0.5502,  0.29999206,  0.68421244,  0.11299734,  0.3125789 ,\n",
    "#         0.69618861, -0.28096646,  0.45888084, -0.27032854,  0.07697116,\n",
    "#        -0.5625567 , -0.58, -0.22702032,  0.07976543, -0.70372301,\n",
    "#        -0.34797056, -0.1152197 ,  0.41478314, -0.49736261,  0.39453689,\n",
    "#        -0.09447947, -0.08091086, -0.40003641,  0.04180626,  0.49347817,\n",
    "#         0.25394288,  0.02494959,  0.53552421,  0.28558491,  0.61067326,\n",
    "#        -0.72650046,-0.32])\n",
    "\n",
    "# ypos=np.array([-0.44942685,  0.0187904 , -0.08720638,  0.7031471 ,  0.11111811,\n",
    "#         0.2784 ,  0.16797938, -0.22899178, -0.07601691,  0.67472988,\n",
    "#         0.23505869,  0.65642641,  0.52935778,  0.36883709,  0.1762651 ,\n",
    "#         0.01505985, -0.4, -0.69954257,  0.41217862, -0.2266678 ,\n",
    "#        -0.06487182,  0.51443979, -0.30910161,  0.51766252, -0.53589769,\n",
    "#        -0.11244721, -0.46289246, -0.56147136, -0.29425527,  0.2757895 ,\n",
    "#        -0.69100594, -0.64317962,  0.01663745,  0.40540164, -0.42807524,\n",
    "#         0.168447,-0.3  ])\n",
    "\n",
    "# rlist=np.array([4.000442 , 4.440296 , 3.7237842, 3.5596673, 3.2063835, 5.4982405,\n",
    "#        4.2089086, 3.0839548, 5.3172565, 3.1439776, 6.364798 , 3.4829168,\n",
    "#        2.767    , 4.3215075, 4.839368 , 4.988825 , 2.8152227, 5.1478076,\n",
    "#        3.409406 , 6.9092703, 4.6986055, 3.2713168, 5.691979 , 4.5658   ,\n",
    "#        4.1020284, 2.970532 , 6.625868 , 7.218    , 3.8116512, 5.8998694,\n",
    "#        2.865156 , 3.6398768, 3.9037654, 2.9168925, 3.3389342, 3.026181 ,\n",
    "#        6.123522 ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_init_model(model,xinit, yinit, rinit, zerninit)\n",
    "#re_init_model(model, xpos,ypos,rlist,zerninit)   # Initialize model with manually entered values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = msu_model(target_res=0.004,aberrations = True)  # zsampling options: 'fixed' or 'uniform_random'\n",
    "load_init_from_file = False\n",
    "# Load initialization from file\n",
    "if load_init_from_file == True:\n",
    "    print('loading initilization from file')\n",
    "    file_best = '/media/hongdata/Kristina/MiniscopeData/best_init.mat'\n",
    "    file_worst = '/media/hongdata/Kristina/MiniscopeData/worst_init.mat'\n",
    "    model = load_model_from_file(model, file_best)\n",
    "    \n",
    "# Save initial values for later comparison \n",
    "re_init_model(model,xinit, yinit, rinit*1.1, zerninit)\n",
    "model.defocus_offset.assign(tf.constant(0*np.random.randn(model.Nz)*1e-5, tf.float64))\n",
    "Rmat=model(0)\n",
    "\n",
    "R_init= Rmat.numpy()\n",
    "Tinit,aper,_= tf_utils.make_lenslet_tf_zern(model)\n",
    "Tinit = Tinit.numpy()\n",
    "aper = aper.numpy()\n",
    "#model_init = msu_model(target_res=0.004, aberrations = True, zernikes = zernikes_index)\n",
    "# model_init = msu_model(Nlenslets = 37, aberrations = False, zernikes = zernikes_index,loss_type='psf_error',psf_scale=1e2,\n",
    "#                   lenslet_CA=0.2e3,lenslet_spacing = 'uniform',psf_file='../psf_meas/nanoscribev1_zstack_june262019_2x_dz40_shifted.mat')\n",
    "#re_init_model(model_init,xinit,yinit,rinit,zerninit)\n",
    "\n",
    "Rmat_init = model(0)\n",
    "\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(Tinit)\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(R_init)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lenslet_offset = tf.zeros(model.Nlenslets,tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_norm_ave = [np.sum(model.target_psf[n].numpy()) for n in range(model.Nz)]\n",
    "# print(psf_norm_ave)\n",
    "# psf_out_normed = [model.target_psf[n].numpy() / psf_norm_ave[n] for n in range(model.Nz)]\n",
    "# print(np.sum(psf_out_normed[0]))\n",
    "# out_dict2 = {'zstack': psf_out_normed}\n",
    "# sc.io.savemat('../psf_meas/nanoscribev1_zstack_june262019_2x_dz40_shifted_center_interp.mat', out_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_zstack =  model.gen_psf_stack(Tinit,.9,0)\n",
    "# psf_zstack_lst = [np.array(psf_zstack[n].numpy()/model.psf_scale) for n in range(model.Nz)]\n",
    "# psf_zstack_arr = np.array(psf_zstack_lst)\n",
    "# save_dict = {\n",
    "#     'zstack':psf_zstack_arr,\n",
    "#     'xpos':model.xpos.numpy(),\n",
    "#     'ypos':model.ypos.numpy(),\n",
    "#     'r':model.rlist.numpy(),\n",
    "#     'zerns':model.zernikes,\n",
    "#     'zern_list':model.zernlist\n",
    "# }\n",
    "# sc.io.savemat(,save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xp = xinit# + tf.random_normal(tf.shape(xinit), stddev=.02)\n",
    "yp = yinit# + tf.random_normal(tf.shape(xinit), stddev=.02)\n",
    "rp = rinit# + tf.random_normal(tf.shape(xinit), stddev=.5)\n",
    "rp = tf.minimum(rp,model.Rmax)\n",
    "tp = tf.maximum(rp,model.Rmin)\n",
    "re_init_model(model,xp,yp,rp,zerninit)\n",
    "Rmat= model(0)\n",
    "Tp,aper,_= tf_utils.make_lenslet_tf_zern(model)\n",
    "aper = aper.numpy()\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].plot(np.array(Rmat))\n",
    "ax[0].set_title('Rmat - random purturbation')\n",
    "\n",
    "ax[1].imshow(Tinit*aper)\n",
    "ax[1].set_title('True surface')\n",
    "\n",
    "ax[2].imshow(Tp*aper)\n",
    "ax[2].set_title('Initialization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(model.target_psf[0],vmax = .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_xy(xloc,yloc,thetad):\n",
    "    #rotmat = [np.cos(theta) -np.sin(theta); np.sin(theta) np.cos(theta)]\n",
    "    \n",
    "    xnew = np.cos(thetad*np.pi/180)*xloc - np.sin(thetad*np.pi/180)*yloc\n",
    "    ynew = np.sin(thetad*np.pi/180)*xloc + np.cos(thetad*np.pi/180)*yloc\n",
    "    return(xnew,ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawnow():\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_noco = msu_model(Nlenslets = 37, aberrations = False, zernikes = zernikes_index,loss_type='psf_error',psf_scale=1e2,\n",
    "#                   lenslet_CA=0.2e3,lenslet_spacing = 'uniform',psf_file='../psf_meas/nanoscribev1_zstack_june262019_2x_dz40_shifted.mat',incoherent_source = False)\n",
    "# re_init_model(model_noco,xinit, yinit, rinit*.6, zerninit)\n",
    "\n",
    "# Tnoco,_,_ = tf_utils.make_lenslet_tf_zern(model)\n",
    "# psf_init_zstack = model_noco.gen_psf_stack(Tnoco,aper,0,defocus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Manually rotate recipe until it qualitatively matches the measured PSF\n",
    "zstart = model.zmin_virtual*1.3\n",
    "zend = model.zmax_virtual*1.1\n",
    "defocus_list = 1./(np.linspace(1/zstart, 1./zend, model.Nz))\n",
    "xrot, yrot = rot_xy(xinit,-yinit,-30)\n",
    "#xrot,yrot = rot_xy(xinit,yinit,0)\n",
    "re_init_model(model, xrot,yrot,rinit*1.0,zerninit)\n",
    "model.defocus_offset.assign(0*tf.ones(model.Nz,tf.float64))\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(20,7))\n",
    "\n",
    "Trot,_,_ = tf_utils.make_lenslet_tf_zern(model)\n",
    "psf_init_zstack = model.gen_psf_stack(Trot,aper,0,1./(1./defocus_list+model.defocus_offset))\n",
    "psf_init_zstack = [tf_utils.tf_2d_conv(psf_init_zstack[n], model.source_kern,'SAME') for n in range(model.Nz)]\n",
    "psf_init_zstack = [psf_init_zstack[n]*tf.reduce_sum(model.target_psf[n] * psf_init_zstack[n])/tf.reduce_sum(psf_init_zstack[n]**2) \n",
    "                      for n in range(model.Nz)]\n",
    "psf_init_zstack = [psf_init_zstack[n].numpy() for n in range(model.Nz)]\n",
    "\n",
    "im_init = ax[0].imshow(psf_init_zstack[0],vmax=.005)\n",
    "cb1 = plt.colorbar(im_init,ax=ax[0])\n",
    "im_targ = ax[1].imshow(model.target_psf[0])\n",
    "cb2 = plt.colorbar(im_targ,ax=ax[1])\n",
    "for n in [9]:\n",
    "    \n",
    "    cb1.remove()\n",
    "    im_init = ax[0].imshow(psf_init_zstack[n],vmax=.003)\n",
    "    cb1 = plt.colorbar(im_init,ax=ax[0])\n",
    "    cb2.remove()\n",
    "    im_targ = ax[1].imshow(model.target_psf[n],vmax=.003)\n",
    "    cb2 = plt.colorbar(im_targ,ax=ax[1])\n",
    "    drawnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_2d_conv(x,y,padstr):\n",
    "    # Inputs x and y tensors (2d)\n",
    "    x_tensor = tf.reshape(x,[1,tf.shape(x)[0], tf.shape(x)[1], 1])\n",
    "    \n",
    "    y_tensor = tf.reshape(y,[tf.shape(y)[0], tf.shape(y)[1],1, 1])\n",
    "    return tf.squeeze(tf.nn.convolution(x_tensor,y_tensor,padstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtest = np.random.rand(5,5)\n",
    "# ytest = np.random.rand(8,9)\n",
    "# ctest = tf_2d_conv(ytest,xtest,'SAME')\n",
    "# print(tf.shape(ctest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Blur PSF to see if match improves\n",
    "\n",
    "# bead_size = 4.8e-3   #mm, diameter\n",
    "# mag = 6.1   #System magnification\n",
    "# bead_size_sensor = np.ceil(bead_size*mag/model.px)\n",
    "\n",
    "# # Construct the circular convolution kernel of size bead_size_sensor (in diameter)\n",
    "# xkern = np.r_[-np.floor(bead_size_sensor/2):np.ceil(bead_size_sensor/2)]\n",
    "# Xkern, Ykern = np.meshgrid(xkern,xkern)\n",
    "# Rkern = np.sqrt(Xkern**2 + Ykern**2)\n",
    "# kern_numpy = (Rkern<=(bead_size_sensor/2)) /np.sum(Rkern)\n",
    "# # Rkern = np.atleast_3d(np.sqrt(Xkern**2 + Ykern**2))\n",
    "# # Rkern = np.moveaxis(Rkern,2,0)\n",
    "\n",
    "# kern = tf.constant(kern_numpy,tf.float64)\n",
    "\n",
    "\n",
    "# tz = 0\n",
    "# target_slice = psf_init_zstack[tz]\n",
    "# slice_blurred = tf_2d_conv(target_slice, kern,'SAME')\n",
    "# #slice_blurred = tf.nn.convolution(model.target_psf, kern,'same')\n",
    "# fit, ax = plt.subplots(2,2,figsize=(20,20))\n",
    "# ax[0,0].imshow(model.target_psf[tz].numpy(),vmax=.03)\n",
    "\n",
    "# ax[0,1].imshow(slice_blurred)\n",
    "\n",
    "# ax[1,0].imshow((target_slice.numpy()/14 - model.target_psf[tz].numpy()))\n",
    "\n",
    "# ax[1,1].imshow((slice_blurred.numpy() - model.target_psf[tz].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bead_kern = tf.constant(np.array())\n",
    "# print(tf.reduce_sum(tf.abs(psf_init_zstack[0] - model.target_psf[0])))\n",
    "# print(tf.reduce_sum(model.target_psf[0]))\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow((psf_init_zstack[1] - model.target_psf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(model.Nz):\n",
    "#     model.target_psf[n]*=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get shifts through zstack\n",
    "# shifts_target_psf = []\n",
    "# f, ax = plt.subplots(1,3,figsize=(25,5))\n",
    "# zstack_shifted = []\n",
    "# for dp in range(model.Nz):\n",
    "\n",
    "#     c = np.fft.ifft2((np.fft.fft2(model.target_psf[dp]))* np.conj(np.fft.fft2(psf_init_zstack[dp])))\n",
    "#     mr = np.unravel_index(np.argmax(c, axis=None), c.shape)\n",
    "    \n",
    "#     mrt = tuple([-mr[n] for n in range(2)])\n",
    "#     im_shifted = np.roll(model.target_psf[dp],mrt,axis=(0,1))\n",
    "\n",
    "#     zstack_shifted.append(im_shifted)\n",
    "#     shifts_target_psf.append(mrt)\n",
    "    \n",
    "    \n",
    "#     ax[0].imshow(im_shifted,vmax=.05)\n",
    "#     ax[1].imshow(psf_init_zstack[dp],vmax=.05)\n",
    "#     ax[1].set_title(mrt)\n",
    "#     ax[2].imshow((im_shifted - psf_init_zstack[dp]),vmin=-.1,vmax=.03)\n",
    "#     drawnow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dict_2={'zstack':zstack_shifted}\n",
    "# sc.io.savemat('../psf_meas/nanoscribev1_zstack_june262019_2x_dz40_shifted.mat',out_dict_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_zstack =  model.gen_psf_stack(Tinit,.9,0)\n",
    "# psf_zstack_lst = [np.array(psf_zstack[n].numpy()) for n in range(model.Nz)]\n",
    "# psf_zstack_arr = np.array(psf_zstack_lst)\n",
    "# sc.io.savemat(\"../psf_meas/zstack_sim_test.mat\",{'zstack':psf_zstack_arr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient (model, myloss, inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        lossvalue, Rmat = myloss(model, inputs)\n",
    "        return tape.gradient(lossvalue, model.variables),lossvalue, Rmat\n",
    "    \n",
    "def gradients_and_scaling(model, loss, inputs):\n",
    "    grad,lossvalue, Rmat=gradient(model,loss, inputs)\n",
    "    \n",
    "    grad[0] = grad[0]\n",
    "    #grad[1] = grad[1] * 1000\n",
    "    #grad[2] = grad[2] * 1000\n",
    "    \n",
    "    grad[1] = grad[1]\n",
    "    grad[2] = grad[2]\n",
    "    grad[3] = grad[3]/1000000000000000\n",
    "\n",
    "    grads=tf_utils.remove_nan_gradients(grad)\n",
    "    return grad, lossvalue, Rmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sensitivity of loss function to lenslet params\n",
    "\n",
    "# defocus_grid = 1./(np.linspace(1/model.zmin_virtual/.8, 1./model.zmax_virtual/.6, model.Nz))\n",
    "# delta = .001;\n",
    "# vars_pert = np.zeros((len(model.variables),model.Nlenslets))\n",
    "# loss_nopert = []\n",
    "# loss_pert = []\n",
    "# for mv in range(len(model.variables)):\n",
    "#     for vi in range(model.Nlenslets):\n",
    "#         re_init_model(model,xinit, yinit, rinit, zerninit)\n",
    "#         loss_nopert.append(tf_utils.loss(model, defocus_grid))\n",
    "#         vars_pert[0,:] = np.copy(rinit)\n",
    "#         vars_pert[1,:] = np.copy(xinit)\n",
    "#         vars_pert[2,:] = np.copy(yinit)\n",
    "#         vars_pert[mv,vi] += delta\n",
    "#         rpert = vars_pert[0,:]\n",
    "#         xpert = vars_pert[1,:]\n",
    "#         ypert = vars_pert[2,:]\n",
    "#         re_init_model(model,xpert, ypert, rpert, zerninit)\n",
    "        \n",
    "#         loss_pert.append(tf_utils.loss(model, defocus_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "defocus_grid = 1./(np.linspace(1/zstart, 1./zend, model.Nz))\n",
    "grad,lossvalue, Rmat=gradient(model,tf_utils.loss, defocus_grid)\n",
    "# grad_nonan = tf_utils.remove_nan_gradients(grad)\n",
    "# grad_array = [grad_nonan[n].numpy() for n in range(len(grad_nonan))]\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(15,5))\n",
    "# loss_vals_nopert = np.array([loss_nopert[n][0] for n in range(len(loss_nopert))])\n",
    "# loss_vals_pert = np.array([loss_pert[n][0] for n in range(len(loss_pert))])\n",
    "# finite_diff_grad = (loss_vals_pert - loss_vals_nopert)/delta\n",
    "# plt.plot(finite_diff_grad,'r',label='finite diff')\n",
    "# plt.plot(np.array(grad_array).ravel(),'k-.',label='tf gradient')\n",
    "# plt.legend()\n",
    "# plt.title('change in loss function caused by wiggling inputs by {}'.format(delta))\n",
    "# plt.xlabel('parameter')\n",
    "# plt.ylabel('d-loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_init_model(model, xrot,yrot,rinit*1.0,zerninit)\n",
    "#re_init_model(model,xinit,yinit,rinit,zerninit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_init = model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_tf(arr,ax):\n",
    "    ndims = arr.ndim\n",
    "    slicer_ = tuple(slice(0+int(n==ax),-1,1) for n in range(ndims))\n",
    "    slicer = tuple(slice(0,-1-int(n==ax),1) for n in range(ndims))\n",
    "    return(arr[slicer_] - arr[slicer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Options:\n",
    "step_size = .1e7/20000. #1e-8 works well for l2\n",
    "use_averaged_gradient = False  # True: uses averaged gradient, False: uses single gradient \n",
    "optimizer_type = 'nesterov'           # options: 'gd': normal gradient descent, 'nesterov': nesterov acceleration\n",
    "num_iterations = 5000\n",
    "num_batches = 1\n",
    "randomize_z = False   #If true, randomize zlist each epoch. If false, leave original order.\n",
    "Rin = model(0)\n",
    "nvars = len(model.variables)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=step_size)\n",
    "#optimizer=tf.train.GradientDescentOptimizer(learning_rate=step_size)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=step_size)\n",
    "#optimizer=tf.train.MomentumOptimizer(learning_rate=step_size,momentum= 0.9, use_nesterov = True)\n",
    "fig, ax = plt.subplots(2,4,figsize=(20,10))\n",
    "\n",
    "Tir = 0\n",
    "Tic = 0\n",
    "ax[Tir,Tic].imshow(Trot)\n",
    "ax[Tir,Tic].set_title('Initial surface')\n",
    "\n",
    "\n",
    "Tor = 0\n",
    "Toc = 1\n",
    "topt = ax[Tor,Toc].imshow(Trot)\n",
    "ax[Tor,Toc].set_title('Optimized surface')\n",
    "\n",
    "Ter = 0\n",
    "Tec = 2\n",
    "imh = ax[Ter,Tec].imshow(Trot - Trot)\n",
    "ax[Ter,Tec].set_title('Phase error')\n",
    "cb = plt.colorbar(imh,ax=ax[Ter,Tec])\n",
    "\n",
    "per = 0\n",
    "pec = 3\n",
    "pl = ax[per,pec].plot([])\n",
    "# ax[per,pec].set_title('phase MSE')\n",
    "ax[per,pec].set_title('focus error')\n",
    "\n",
    "lr = 1\n",
    "lc = 0\n",
    "l = ax[lr,lc].plot([])\n",
    "ax[lr,lc].set_title('Loss')\n",
    "\n",
    "xyr = 1\n",
    "xyc = 1\n",
    "lh = ax[xyr,xyc].scatter(model.xpos.numpy(),model.ypos.numpy(),c='k', marker='.',label='init')\n",
    "lh = ax[xyr,xyc].scatter(model.xpos.numpy(),model.ypos.numpy(),c='b', marker='.',label='opt')\n",
    "ax[xyr,xyc].scatter(xinit*0/0,yinit,c='r',marker='x',label='target')\n",
    "ax[xyr,xyc].axis('equal')\n",
    "\n",
    "rr = 1\n",
    "rc = 2\n",
    "ax[rr,rc].plot(model.rlist.numpy(),'k.',label='init')\n",
    "rh = ax[rr,rc].plot(model.rlist.numpy(),'b.',label='opt')\n",
    "ax[rr,rc].plot(rinit*0/0,'rx',label='target')\n",
    "\n",
    "\n",
    "Rr = 1\n",
    "Rc = 3\n",
    "Rh = ax[Rr,Rc].plot(Rin.numpy())\n",
    "gradr = ax[Rr,Rc].plot(model.rlist.numpy(),'r',label='R')\n",
    "gradx = ax[Rr,Rc].plot(model.xpos.numpy(),'g',label='X')\n",
    "grady  = ax[Rr,Rc].plot(model.ypos.numpy(),'b',label='Y')\n",
    "\n",
    "\n",
    "losslist = []\n",
    "phase_err = []\n",
    "rmean=[]\n",
    "\n",
    "#defocus_grid=  1./(np.linspace(1/model.zmin_virtual, 1./model.zmax_virtual, model.Nz * num_batches)) #mm or dioptres\n",
    "#defocus_grid = 1./(np.linspace(1/model.zmin_virtual, 1./model.zmax_virtual/.6, model.Nz))  \n",
    "defocus_grid = 1./(np.linspace(1/zstart, 1./zend, model.Nz))\n",
    "\n",
    "if optimizer_type == 'nesterov':\n",
    "    tk = tf.constant(1,tf.float64)\n",
    "    tkp = tf.constant(1,tf.float64)\n",
    "\n",
    "    #xkp = model.variables\n",
    "    nvars = np.shape(model.variables)[0]\n",
    "    xk = []\n",
    "    xkp = []\n",
    "    [xk.append(tf.Variable(tf.zeros(tf.size(model.variables[n]),tf.float64))) for n in range(nvars)]\n",
    "    [xkp.append(tf.Variable(tf.zeros(tf.size(model.variables[n]),tf.float64))) for n in range(nvars)]\n",
    "    [tf.assign(xkp[n],model.variables[n]) for n in range(nvars)]\n",
    "\n",
    "lossbest = 1e10\n",
    "for i in range(num_iterations):\n",
    "    if randomize_z:\n",
    "        defocus_epoch = np.random.permutation(defocus_grid)\n",
    "    else:\n",
    "        defocus_epoch = defocus_grid\n",
    "    for j in range(num_batches):\n",
    "        if use_averaged_gradient == True:\n",
    "            grad,lossvalue, Rmat =  averaged_gradient(model, tf_utils.loss, num_averages = 10)\n",
    "        else: \n",
    "            grad, lossvalue, Rmat = gradients_and_scaling(model, tf_utils.loss, defocus_epoch[j*model.Nz:j*model.Nz+model.Nz])  # initial value \n",
    "\n",
    "\n",
    "        #grad,lossvalue, Rmat=gradient(model,loss)\n",
    "\n",
    "       # new_xpos = model.xpos - step_size*grad[2]\n",
    "       # new_ypos = model.xpos - step_size*grad[3] \n",
    "        #new_grad, test_dist, test_dist_bool = constrain_distances(model, new_xpos, new_ypos, grad) # apply constraint \n",
    "\n",
    "\n",
    "        # Gradient step\n",
    "        if optimizer_type == 'gd':\n",
    "            optimizer.apply_gradients(zip(grad,model.variables),global_step=tf.train.get_or_create_global_step())\n",
    "            # Projection step\n",
    "            tf_utils.project_to_aper_keras(model)\n",
    "\n",
    "        if optimizer_type == 'nesterov':\n",
    "\n",
    "            optimizer.apply_gradients(zip(grad,model.variables),global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "\n",
    "            # Projection step\n",
    "            tf_utils.project_to_aper_keras(model,1100)\n",
    "\n",
    "            # Update variables for next loop\n",
    "            tk = tkp\n",
    "            [tf.assign(xk[n],xkp[n]) for n in range(nvars)]\n",
    "\n",
    "            # Get state after project (gradient_step(yk))\n",
    "            [tf.assign(xkp[n],model.variables[n]) for n in range(nvars)]\n",
    "\n",
    "            #Acceleration\n",
    "            tkp = 0.5*(1.0 + tf.sqrt(1.0 + 4*tf.square(tk)))\n",
    "\n",
    "            bkp = (tk - 1)/tkp\n",
    "            ykp = [xkp[n] + bkp*(xkp[n] - xk[n]) for n in range(nvars)]\n",
    "\n",
    "\n",
    "            # Update model variables (yk)\n",
    "            [model.variables[n].assign(ykp[n]) for n in range(nvars)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        T,aper,T2=tf_utils.make_lenslet_tf_zern(model)\n",
    "        found_better = False\n",
    "        if lossvalue <= lossbest:\n",
    "            found_better = True\n",
    "            bestvars = model.variables\n",
    "            rbest = bestvars[0].numpy()\n",
    "            xbest = bestvars[1].numpy()\n",
    "            ybest = bestvars[2].numpy()\n",
    "            defocus_best = bestvars[3].numpy()\n",
    "            lossbest = lossvalue\n",
    "        else:\n",
    "            tk = tf.constant(1.,tf.float64)\n",
    "            tkp = tf.constant(1.,tf.float64)\n",
    "            \n",
    "        losslist.append(lossvalue)\n",
    "        phase_err.append(.5*tf.norm(T - Tinit)**2/model.samples[0]/model.samples[1])\n",
    "\n",
    "        \n",
    "        topt.remove()\n",
    "        topt = ax[Tor,Toc].imshow(T)\n",
    "        ax[Tor,Toc].set_title(\"Optimized surface, iter {}\".format(i))\n",
    "\n",
    "        l[0].remove()\n",
    "        l = ax[lr,lc].plot(losslist,'k')\n",
    "        ax[lr,lc].set_title('Loss (best = {})'.format(found_better))\n",
    "        \n",
    "        pl[0].remove()\n",
    "        pl = ax[per,pec].plot(model.defocus_offset.numpy(),'k')\n",
    "        \n",
    "#        ax[per,pec].set_title('phase MSE')\n",
    "\n",
    "        ax[per,pec].set_title('focus error')\n",
    "        \n",
    "        cb.remove()\n",
    "        imh.remove()\n",
    "        \n",
    "        imh = ax[Ter,Tec].imshow((T - Trot))\n",
    "        ax[Ter,Tec].set_title('Phase diff micron')\n",
    "        cb = plt.colorbar(imh,ax=ax[Ter,Tec])\n",
    "\n",
    "        \n",
    "        lh.remove()\n",
    "        lh = ax[xyr,xyc].scatter(model.xpos.numpy(),model.ypos.numpy(),c='b', marker='.',label='opt')\n",
    "        ax[xyr,xyc].legend()\n",
    "        ax[xyr,xyc].set_title('Positions')\n",
    "        \n",
    "        Rh[0].remove()\n",
    "        gradr[0].remove()\n",
    "        gradx[0].remove()\n",
    "        grady[0].remove()\n",
    "        Rh = ax[Rr,Rc].semilogy(Rmat.numpy(),'k')\n",
    "        gradr = ax[Rr,Rc].semilogy(grad[0].numpy(),'r',label='R')\n",
    "        gradx = ax[Rr,Rc].semilogy(grad[1].numpy(),'g',label='X')\n",
    "        grady  = ax[Rr,Rc].semilogy(grad[2].numpy(),'b',label='Y')\n",
    "        \n",
    "        ax[Rr,Rc].legend()\n",
    "        #ax[Rr,Rc].set_title('gradient')\n",
    "        ax[Rr,Rc].set_title('Rmat and grads')\n",
    "        \n",
    "        \n",
    "        rh[0].remove()\n",
    "        rh = ax[rr,rc].plot(model.rlist.numpy(),'b.',label='opt')\n",
    "        ax[rr,rc].legend()\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "#     pl.remove?\n",
    "    \n",
    "\n",
    "\n",
    "#cbar = fig.colorbar(rshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zstack_test = [psf_init_zstack[n]*tf.reduce_sum(model.target_psf[n] * psf_init_zstack[n])/tf.reduce_sum(psf_init_zstack[n]**2) \n",
    "                      for n in range(model.Nz)]\n",
    "\n",
    "scale_list = [tf.reduce_sum(model.target_psf[n] * psf_init_zstack[n])/tf.reduce_sum(psf_init_zstack[n]**2) \n",
    "                      for n in range(model.Nz)]\n",
    "print(np.array(scale_list))\n",
    "print(\"Scaled {}\".format(tf.reduce_sum(tf.abs(zstack_test[0] - model.target_psf[0])**2)))\n",
    "print(\"unscaled {}\".format(tf.reduce_sum(tf.abs(psf_init_zstack[0] - model.target_psf[0])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_final = model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_good = sc.io.loadmat('../l1_scaled_lenslet_fit_nanoscribe_v1_20190812_173906.mat')\n",
    "# xgood = model_good['xbest'][0].astype(np.float64)\n",
    "# ygood = model_good['ybest'][0].astype(np.float64)\n",
    "# rgood = model_good['rbest'][0].astype(np.float64)\n",
    "# defocus_good = model_good['defocus_list'][0].astype(np.float64)\n",
    "# zerngood = model_orig['zern_list']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "bead_size = 4.8   #mm, diameter\n",
    "mag = 6.1   #System magnification\n",
    "bead_size_sensor = np.ceil(bead_size*mag/model.px)\n",
    "re_init_model(model,xbest,ybest,rbest,zerninit,defocus_best)\n",
    "Topt,_,_ = tf_utils.make_lenslet_tf_zern(model)\n",
    "psf_opt_zstack = model.gen_psf_stack(Topt,aper,0,1./(1./defocus_list + model.defocus_offset))\n",
    "\n",
    "psf_opt_zstack = [tf_utils.tf_2d_conv(psf_opt_zstack[n], model.source_kern,'SAME') for n in range(model.Nz)]\n",
    "psf_opt_zstack = [psf_opt_zstack[n]*tf.reduce_sum(model.target_psf[n] * psf_opt_zstack[n])/tf.reduce_sum(psf_opt_zstack[n]**2) \n",
    "                      for n in range(model.Nz)]\n",
    "\n",
    "psf_opt_zstack = [psf_opt_zstack[n].numpy() for n in range(model.Nz)]\n",
    "\n",
    "# best_dict = {\n",
    "#     'xpos':xbest,\n",
    "#     'ypos':ybest,\n",
    "#     'rlist':rbest,\n",
    "#     'zstack_best':psf_opt_zstack,\n",
    "#     'defocus_list':defocus_grid,\n",
    "#     'defocus_correction':model.defocus_offset,\n",
    "#     'loss':losslist\n",
    "# }\n",
    "\n",
    "# dt = datetime.datetime.now()\n",
    "# dts = dt.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# sc.io.savemat('../l1_GOOD_scaled_nanoscribe_v1_' + dts + '.mat',best_dict)\n",
    "tz =0\n",
    "target_slice = psf_opt_zstack[tz]\n",
    "# slice_blurred = tf_2d_conv(target_slice, model.source_kern,'SAME')\n",
    "#slice_blurred = tf.nn.convolution(model.target_psf, kern,'same')\n",
    "fit, ax = plt.subplots(1,3,figsize=(20,10))\n",
    "ax[0].imshow(model.target_psf[tz].numpy(),vmax=.005)\n",
    "\n",
    "ax[1].imshow(psf_opt_zstack[tz],vmax=.005)\n",
    "\n",
    "\n",
    "ax[2].imshow((psf_opt_zstack[tz] - model.target_psf[tz].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get shifts through zstack\n",
    "shifts_target_psf = []\n",
    "f, ax = plt.subplots(1,3,figsize=(25,5))\n",
    "zstack_shifted = []\n",
    "for dp in range(model.Nz):\n",
    "\n",
    "    c = np.fft.ifft2((np.fft.fft2(model.target_psf[dp]))* np.conj(np.fft.fft2(psf_opt_zstack[dp])))\n",
    "    mr = np.unravel_index(np.argmax(c, axis=None), c.shape)\n",
    "    \n",
    "    mrt = tuple([-mr[n] for n in range(2)])\n",
    "    im_shifted = np.roll(model.target_psf[dp].numpy(),mrt,axis=(0,1))\n",
    "\n",
    "    zstack_shifted.append(im_shifted/model.psf_scale.numpy())\n",
    "    shifts_target_psf.append(mrt)\n",
    "    \n",
    "    \n",
    "    ax[0].imshow(im_shifted,vmax=.005)\n",
    "    ax[1].imshow(psf_opt_zstack[dp],vmax=.005)\n",
    "    ax[1].set_title(mrt)\n",
    "    ax[2].imshow((im_shifted - psf_opt_zstack[dp]),vmin=-.01,vmax=.01)\n",
    "    drawnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.roll(model.target_psf[dp].numpy(),mrt,axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.io.savemat('../psf_meas/psf_crop_nanoscribe_v1_re-registered.mat',{'zstack':zstack_shifted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dict = {\n",
    "    'xpos':xbest,\n",
    "    'ypos':ybest,\n",
    "    'rlist':rbest,\n",
    "    'zstack_best':psf_opt_zstack,\n",
    "    'defocus_list':defocus_grid,\n",
    "    'defocus_correction':model.defocus_offset,\n",
    "    'loss':losslist\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dict['defocus_correction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bead_size = 4.8   #um, diameter\n",
    "mag = 6.1   #System magnification\n",
    "bead_size_sensor = np.ceil(bead_size*mag/model.px)\n",
    "xkern = np.r_[-np.floor(bead_size_sensor/2):np.ceil(bead_size_sensor/2)]\n",
    "Xkern, Ykern = np.meshgrid(xkern,xkern)\n",
    "Rkern = np.sqrt(Xkern**2 + Ykern**2)\n",
    "kern_numpy = (Rkern<=(bead_size_sensor/2)) /np.sum(Rkern)\n",
    "kern = tf.constant(kern_numpy,tf.float32)\n",
    "#test_zstack = [tf_2d_conv(psf_opt_zstack[n], kern,'SAME') for n in range(len(psf_opt_zstack))]\n",
    "test_zstack = []\n",
    "[test_zstack[n] = tf_2d_conv(psf_opt_zstack[n], kern,'SAME') for n in range(len(psf_opt_zstack))]\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(np.abs(test_zstack[3]),vmax=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.r_[-np.floor(bead_size_sensor/2):np.ceil(bead_size_sensor/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad, lossvalue, Rmat = gradients_and_scaling(model, tf_utils.loss, defocus_epoch[j*model.Nz:j*model.Nz+model.Nz])  # initial value \n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.variables[0] - rinit*.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T,aper,T2=tf_utils.make_lenslet_tf_zern(model)\n",
    "\n",
    "print(model.min_r)\n",
    "print(model.max_r)\n",
    "\n",
    "a = lambda t: tf.clip_by_value(t,model.min_r, model.max_r)\n",
    "print(a(model.rlist)/ model.rlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(defocus_epoch[j*model.Nz:j*model.Nz+model.Nz])\n",
    "print(defocus_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(psf_init_zstack[0]-model.target_psf[0],vmin=-100,vmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(losslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh = ax[xyr,xyc].scatter(model.xpos.numpy(),model.ypos.numpy(),c='b', marker='x')\n",
    "\n",
    "print(nvars)\n",
    "imh.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "sphere = tf.real(tf.sqrt(\n",
    "    tf.square(model.rlist[n])\n",
    "    - tf.square((model.xgm-model.xpos[n]))\n",
    "    - tf.square((model.ygm-model.ypos[n]))))\n",
    "\n",
    "piston = tf.real\n",
    "(\n",
    "    tf.sqrt\n",
    "    (\n",
    "        tf.square(model.rlist[n])-tf.square(model.mean_lenslet_CA)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(model.rlist.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.rlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tgd,_,_= tf_utils.make_lenslet_tf_zern(model)\n",
    "psf_zstack =  model.gen_psf_stack(Tgd,.9,.5)\n",
    "vup =.05\n",
    "#zdisp = 0\n",
    "f, ax = plt.subplots(2,2,figsize=(12,12))\n",
    "for zdisp in range(1):\n",
    "    ax[0,0].imshow(model.target_psf[zdisp],vmax = vup)\n",
    "    ax[0,0].set_title('target')\n",
    "    ax[0,1].imshow(psf_zstack[zdisp],vmax=vup)\n",
    "    ax[0,1].set_title('Optimized')\n",
    "    ax[1,0].imshow(Tinit)\n",
    "    ax[1,0].set_title('target')\n",
    "    \n",
    "    if zdisp != 0:\n",
    "        cb.remove()\n",
    "        e.remove()\n",
    "\n",
    "    e = ax[1,1].imshow(model.target_psf[zdisp] - psf_zstack[zdisp])\n",
    "   \n",
    "    ax[1,1].set_title('error')\n",
    "    cb = plt.colorbar(e,ax=ax[1,1])\n",
    "    \n",
    "    \n",
    "    display.display(f)\n",
    "    display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rinit.numpy(),label='init')\n",
    "plt.plot(model.rlist.numpy(),label='opt')\n",
    "plt.legend()\n",
    "model_init.ypos.numpy() - model.ypos.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:eager-latest]",
   "language": "python",
   "name": "conda-env-eager-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
